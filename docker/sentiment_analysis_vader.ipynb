{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "67fe9b1b",
   "metadata": {},
   "source": [
    "# Objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "789d77d0",
   "metadata": {},
   "source": [
    "1. What is **Sentiment Analysis** ? what practical use cases does it have ?\n",
    "2. Rule-based sentiment analysis using Vader \n",
    "3. What other approaches can be used for **Sentiment Analysis** ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01415e59",
   "metadata": {},
   "source": [
    "# Warm-up"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cde79cc",
   "metadata": {},
   "source": [
    "**Take a look at the [Vader-github-repo](https://github.com/cjhutto/vaderSentiment) and try to answer these questions:**\n",
    "\n",
    "1. What is sentiment analysis ?\n",
    "\n",
    "2. What can we find in the **lexicon**, and more specifically: what are the four values representing ? \n",
    "\n",
    "3. Does Vader take punctuation into account ? Which words does Vader consider to intensify a sentiment ?\n",
    "\n",
    "4. How does Vader score a text as a whole ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0952fdc",
   "metadata": {},
   "source": [
    "## **1. What is Sentiment Analysis ?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb7d737f",
   "metadata": {},
   "source": [
    "**1. What is Sentiment Analysis ?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd8c7a7e",
   "metadata": {},
   "source": [
    "- Sentiment analysis is simply the process of working out (statistically) whether a piece of text is positive, negative or neutral\n",
    "- The majority of sentiment analysis approaches take one of two forms: \n",
    "1. polarity-based, where pieces of texts are classified as either positive or negative\n",
    "2. valence-based, where the intensity of the sentiment is taken into account For example, the words â€˜goodâ€™ and â€˜excellentâ€™ would be treated the same in a polarity-based approach, whereas â€˜excellentâ€™ would be treated as more positive than â€˜goodâ€™ in a valence-based approach\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "419f0e95",
   "metadata": {},
   "source": [
    "**2. What can we find in the *lexicon*, and more specifically: what are the four values representing ?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9b87ce6",
   "metadata": {},
   "source": [
    "- Vader lexicon is in the text file *vader_lexicon.txt*\n",
    "- the file is tab delimited with TOKEN, MEAN-SENTIMENT-RATING, STANDARD DEVIATION, and RAW-HUMAN-SENTIMENT-RATINGS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f2885de",
   "metadata": {},
   "source": [
    "**3. Does vader take punctuation into account? Which words does Vader consider to intensify a sentiment ?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9c2d9f5",
   "metadata": {},
   "source": [
    "Vader is trained on twitter text and it takes the following into consideration:\n",
    "\n",
    "- typical negations (e.g., \"not good\")\n",
    "- use of contractions as negations (e.g., \"wasn't very good\")\n",
    "- conventional use of punctuation to signal increased sentiment intensity (e.g., \"Good!!!\")\n",
    "- conventional use of word-shape to signal emphasis (e.g., using ALL CAPS for words/phrases)\n",
    "- using degree modifiers to alter sentiment intensity (e.g., intensity boosters such as \"very\" and intensity dampeners such as \"kind of\")\n",
    "- understanding many sentiment-laden slang words (e.g., 'sux')\n",
    "- understanding many sentiment-laden slang words as modifiers such as 'uber' or 'friggin' or 'kinda'\n",
    "- understanding many sentiment-laden emoticons such as :) and :D\n",
    "- translating utf-8 encoded emojis such as ðŸ’˜ and ðŸ’‹ and ðŸ˜\n",
    "- understanding sentiment-laden initialisms and acronyms (for example: 'lol')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c010f783",
   "metadata": {},
   "source": [
    "**4. How does Vader score a text as a whole ?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37675d84",
   "metadata": {},
   "source": [
    "- Vader gives each text the following scores: pos, compount, neu, neg\n",
    "- The pos, neu, and neg scores are ratios for proportions of text that fall in each category (so these should all add up to be 1... or close to it with float operation)\n",
    "- The compound score is computed by summing the valence scores of each word in the lexicon, adjusted according to the rules, and then normalized to be between -1 (most extreme negative) and +1 (most extreme positive)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "843b5190",
   "metadata": {},
   "source": [
    "## 2. Rule-based sentiment analysis using Vader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b96de1dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "analyser = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "686259a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_sentiment_scores(sentence):\n",
    "    snt = analyser.polarity_scores(sentence)\n",
    "    print(\"{} : {}\".format(sentence, str(snt)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "637d75e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I just got a call from my boss - does he realise it's Saturday? : {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n"
     ]
    }
   ],
   "source": [
    "print_sentiment_scores(\"I just got a call from my boss - does he realise it's Saturday?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "198f2f98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I just got a call from my boss - does he realise it's Saturday? :( : {'neg': 0.172, 'neu': 0.828, 'pos': 0.0, 'compound': -0.4404}\n"
     ]
    }
   ],
   "source": [
    "# what happens when we add an emoticon ?\n",
    "\n",
    "print_sentiment_scores(\"I just got a call from my boss - does he realise it's Saturday? :(\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d8a167ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I just got a call from my boss - does he realise it's Saturday? smh :( : {'neg': 0.271, 'neu': 0.729, 'pos': 0.0, 'compound': -0.6369}\n"
     ]
    }
   ],
   "source": [
    "# Letâ€™s now add the acronym â€˜smhâ€™ (shaking my head) and see what happens\n",
    "\n",
    "print_sentiment_scores(\"I just got a call from my boss - does he realise it's Saturday? smh :(\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "32f42219",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The food is good. : {'neg': 0.0, 'neu': 0.508, 'pos': 0.492, 'compound': 0.4404}\n"
     ]
    }
   ],
   "source": [
    "# Vader can also \"understand\" word context \n",
    "\n",
    "print_sentiment_scores(\"The food is good.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "28a5dcfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The food is GOOD. : {'neg': 0.0, 'neu': 0.452, 'pos': 0.548, 'compound': 0.5622}\n"
     ]
    }
   ],
   "source": [
    "# let's introduce capitalization\n",
    "\n",
    "print_sentiment_scores(\"The food is GOOD.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "21112b2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The food is GOOD!! : {'neg': 0.0, 'neu': 0.416, 'pos': 0.584, 'compound': 0.639}\n"
     ]
    }
   ],
   "source": [
    "# Another factor that increases the intensity of sentence sentiment is exclamation mark\n",
    "\n",
    "print_sentiment_scores(\"The food is GOOD!!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e01e4816",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The food is really GOOD!! : {'neg': 0.0, 'neu': 0.47, 'pos': 0.53, 'compound': 0.6715}\n"
     ]
    }
   ],
   "source": [
    "# VADER also takes into account what happens when modifying words are present in front of a sentiment term\n",
    "# For example, â€œextremely badâ€ would increase the negative intensity of a sentence, but â€œkinda badâ€ would decrease it\n",
    "\n",
    "print_sentiment_scores(\"The food is really GOOD!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "adee84ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The food is kinda GOOD!! : {'neg': 0.0, 'neu': 0.505, 'pos': 0.495, 'compound': 0.6025}\n"
     ]
    }
   ],
   "source": [
    "print_sentiment_scores(\"The food is kinda GOOD!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9b899a19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The food is really GOOD! But the service is dreadful. : {'neg': 0.284, 'neu': 0.548, 'pos': 0.169, 'compound': -0.3977}\n"
     ]
    }
   ],
   "source": [
    "# VADER also handles changes in a sentenceâ€™s sentiment intensity when it contains â€˜butâ€™\n",
    "# Essentially, the rule is that the sentiments expressed both before and after the â€˜butâ€™ are taken into consideration \n",
    "# However, the sentiment afterwards is weighted more heavily than that before\n",
    "\n",
    "print_sentiment_scores(\"The food is really GOOD! But the service is dreadful.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32cf9f5b",
   "metadata": {},
   "source": [
    "## 3. What other approaches can be used for Sentiment Analysis ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb89984f",
   "metadata": {},
   "source": [
    "1. Classical Machine Learning NLP approaches: \n",
    "- Bag-of-words and Naive Bayes work to some extent for simpler sentiment analysis tasks\n",
    "- Support Vector Machines are used to model complex content\n",
    "\n",
    "2. Rule-based ==> Vader for example\n",
    "\n",
    "3. Deep Learning approaches ==> examples: Word2vec and LSTM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28efd6c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
