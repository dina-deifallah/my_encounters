{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feed-forward and backprop from scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feed-forward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div>\n",
    "<img src=\"feedforward.png\" width=\"500\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1: Create training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_moons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_moons(n_samples=50, noise=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2: Take a look at the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 2)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50,)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(X[:,0], X[:,1], c=y);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3: Add a bias (parameter b) column to X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.15856989,  0.98480618,  1.        ],\n",
       "       [ 1.10900374, -0.62160223,  1.        ],\n",
       "       [ 0.39641523,  0.20740869,  1.        ],\n",
       "       [ 1.79239122,  0.07511293,  1.        ],\n",
       "       [-0.84739307,  0.71154296,  1.        ],\n",
       "       [ 1.90209657,  0.67432213,  1.        ],\n",
       "       [ 0.0731551 ,  0.09079042,  1.        ],\n",
       "       [-0.43566685,  0.29122072,  1.        ],\n",
       "       [ 0.42577731, -0.22851359,  1.        ],\n",
       "       [-0.64418143,  0.24144478,  1.        ],\n",
       "       [ 0.11289285,  1.00510013,  1.        ],\n",
       "       [ 0.96066405,  0.63183812,  1.        ],\n",
       "       [ 1.46814927, -0.28580296,  1.        ],\n",
       "       [ 0.5192833 ,  0.94984582,  1.        ],\n",
       "       [ 0.73327397,  0.17310931,  1.        ],\n",
       "       [ 0.33197143,  0.43375035,  1.        ],\n",
       "       [ 1.62726102, -0.54736954,  1.        ],\n",
       "       [ 2.01908805,  0.37804882,  1.        ],\n",
       "       [ 2.00824323,  0.36058988,  1.        ],\n",
       "       [-0.56195047,  0.90148197,  1.        ],\n",
       "       [ 0.67647169,  0.69909987,  1.        ],\n",
       "       [-0.30999892,  1.2113287 ,  1.        ],\n",
       "       [-0.90842298, -0.33685748,  1.        ],\n",
       "       [ 0.68268561, -0.44010332,  1.        ],\n",
       "       [ 0.38645217, -0.05988231,  1.        ],\n",
       "       [ 0.84405962, -0.16877927,  1.        ],\n",
       "       [ 1.76324657, -0.30187296,  1.        ],\n",
       "       [ 0.06417199,  0.2184967 ,  1.        ],\n",
       "       [ 1.02670564, -0.57104358,  1.        ],\n",
       "       [ 0.63694378,  0.69355004,  1.        ],\n",
       "       [ 0.30851562,  0.4574452 ,  1.        ],\n",
       "       [ 0.45511029,  1.15619148,  1.        ],\n",
       "       [ 0.92808566, -0.31211878,  1.        ],\n",
       "       [ 0.86938046,  0.06729301,  1.        ],\n",
       "       [-1.22036438,  0.33691393,  1.        ],\n",
       "       [ 1.15845408,  0.21688056,  1.        ],\n",
       "       [ 1.5522982 , -0.27906241,  1.        ],\n",
       "       [ 0.88599761, -0.51707875,  1.        ],\n",
       "       [-0.82146062, -0.13173865,  1.        ],\n",
       "       [ 1.20862244, -0.52520818,  1.        ],\n",
       "       [-0.00317109,  1.55465851,  1.        ],\n",
       "       [-1.18517899,  0.44179591,  1.        ],\n",
       "       [-0.84031891,  0.60434928,  1.        ],\n",
       "       [ 2.06026456,  0.20829662,  1.        ],\n",
       "       [-0.99857307,  0.47070544,  1.        ],\n",
       "       [ 0.43955803,  0.62885547,  1.        ],\n",
       "       [ 1.82610683, -0.09235596,  1.        ],\n",
       "       [-0.34717225,  0.94909281,  1.        ],\n",
       "       [ 0.32352368, -0.16797921,  1.        ],\n",
       "       [ 1.19813072, -0.09653062,  1.        ]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.hstack([X, np.ones((X.shape[0], 1))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_bias(X):\n",
    "    \n",
    "    return  np.hstack([X, np.ones((X.shape[0], 1))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = add_bias(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.15856989,  0.98480618,  1.        ],\n",
       "       [ 1.10900374, -0.62160223,  1.        ],\n",
       "       [ 0.39641523,  0.20740869,  1.        ],\n",
       "       [ 1.79239122,  0.07511293,  1.        ],\n",
       "       [-0.84739307,  0.71154296,  1.        ],\n",
       "       [ 1.90209657,  0.67432213,  1.        ],\n",
       "       [ 0.0731551 ,  0.09079042,  1.        ],\n",
       "       [-0.43566685,  0.29122072,  1.        ],\n",
       "       [ 0.42577731, -0.22851359,  1.        ],\n",
       "       [-0.64418143,  0.24144478,  1.        ],\n",
       "       [ 0.11289285,  1.00510013,  1.        ],\n",
       "       [ 0.96066405,  0.63183812,  1.        ],\n",
       "       [ 1.46814927, -0.28580296,  1.        ],\n",
       "       [ 0.5192833 ,  0.94984582,  1.        ],\n",
       "       [ 0.73327397,  0.17310931,  1.        ],\n",
       "       [ 0.33197143,  0.43375035,  1.        ],\n",
       "       [ 1.62726102, -0.54736954,  1.        ],\n",
       "       [ 2.01908805,  0.37804882,  1.        ],\n",
       "       [ 2.00824323,  0.36058988,  1.        ],\n",
       "       [-0.56195047,  0.90148197,  1.        ],\n",
       "       [ 0.67647169,  0.69909987,  1.        ],\n",
       "       [-0.30999892,  1.2113287 ,  1.        ],\n",
       "       [-0.90842298, -0.33685748,  1.        ],\n",
       "       [ 0.68268561, -0.44010332,  1.        ],\n",
       "       [ 0.38645217, -0.05988231,  1.        ],\n",
       "       [ 0.84405962, -0.16877927,  1.        ],\n",
       "       [ 1.76324657, -0.30187296,  1.        ],\n",
       "       [ 0.06417199,  0.2184967 ,  1.        ],\n",
       "       [ 1.02670564, -0.57104358,  1.        ],\n",
       "       [ 0.63694378,  0.69355004,  1.        ],\n",
       "       [ 0.30851562,  0.4574452 ,  1.        ],\n",
       "       [ 0.45511029,  1.15619148,  1.        ],\n",
       "       [ 0.92808566, -0.31211878,  1.        ],\n",
       "       [ 0.86938046,  0.06729301,  1.        ],\n",
       "       [-1.22036438,  0.33691393,  1.        ],\n",
       "       [ 1.15845408,  0.21688056,  1.        ],\n",
       "       [ 1.5522982 , -0.27906241,  1.        ],\n",
       "       [ 0.88599761, -0.51707875,  1.        ],\n",
       "       [-0.82146062, -0.13173865,  1.        ],\n",
       "       [ 1.20862244, -0.52520818,  1.        ],\n",
       "       [-0.00317109,  1.55465851,  1.        ],\n",
       "       [-1.18517899,  0.44179591,  1.        ],\n",
       "       [-0.84031891,  0.60434928,  1.        ],\n",
       "       [ 2.06026456,  0.20829662,  1.        ],\n",
       "       [-0.99857307,  0.47070544,  1.        ],\n",
       "       [ 0.43955803,  0.62885547,  1.        ],\n",
       "       [ 1.82610683, -0.09235596,  1.        ],\n",
       "       [-0.34717225,  0.94909281,  1.        ],\n",
       "       [ 0.32352368, -0.16797921,  1.        ],\n",
       "       [ 1.19813072, -0.09653062,  1.        ]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 4: calculate the sigmoid activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([-10.0, -1.0, 0.0, 1.0, 10.0])\n",
    "expected = np.array([0.0, 0.27, 0.5, 0.73, 1.0])\n",
    "assert np.all(sigmoid(a).round(2) == expected)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 5: Initialize the weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_neurons = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = []\n",
    "w.append(np.random.randn(X.shape[1], n_neurons)) # first layer\n",
    "w.append(np.random.randn(n_neurons+1, 1)) # second layer/hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[-0.66299053, -0.81279448],\n",
       "        [ 0.05916487,  0.37925358],\n",
       "        [ 1.20695721, -0.14899306]]),\n",
       " array([[-0.28244138],\n",
       "        [-0.95269417],\n",
       "        [-0.65529188]])]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 6: Put it all together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feed_forward(X, weights):\n",
    "\n",
    "    \"\"\"\n",
    "    1. Multiply the input matrix X\n",
    "       with the weights of the first layer.\n",
    "    \"\"\"\n",
    "    step1 = np.dot(X, weights[0])\n",
    "\n",
    "    \"\"\"\n",
    "    2. Apply the sigmoid function on the result.\n",
    "    \"\"\"\n",
    "    step2 = sigmoid(step1)\n",
    "\n",
    "    \"\"\"\n",
    "     3. Append an extra column of ones to the result (i.e. the bias).\n",
    "\n",
    "    \"\"\"\n",
    "    step3 = add_bias(step2)\n",
    "    \n",
    "    \"\"\"\n",
    "     4. Multiply the output of the previous step\n",
    "       with the weights of the second (i.e. outer) layer.\n",
    "    \"\"\"\n",
    "    step4 = np.dot(step3, weights[1])\n",
    "\n",
    "    \"\"\"\n",
    "    5. Apply the sigmoid function on the result.\n",
    "    \"\"\"\n",
    "    step5 = sigmoid(step4)\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    6. Return all intermediate results (i.e. anything that is outputted\n",
    "       by an activation function).\n",
    "    \"\"\"\n",
    "    \n",
    "\n",
    "    return step2, step5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "out1, out2 = feed_forward(X, w)\n",
    "assert out1.shape == (50, 2)\n",
    "assert out2.shape == (50, 1)\n",
    "\n",
    "Xref = np.array([[1.0, 2.0, 1.0]])\n",
    "whidden = np.array([[1.0, 2.0, 0.0],\n",
    "                 [-1.0, -2.0, 0.0]\n",
    "                    ]).T\n",
    "wout = np.array([[1.0, -1.0, 0.5]]).T\n",
    "\n",
    "out1, out2 = feed_forward(Xref, [whidden, wout])\n",
    "assert np.all(out1.round(2) == np.array([[0.99, 0.01]]))\n",
    "assert np.all(out2.round(2) == np.array([[0.82]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Backpropagation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div>\n",
    "<img src=\"neuron_w_backprop.png\" width=\"500\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Let's talk about loss function!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Here we'll use log loss as a loss function:\n",
    "$$ loss = -(y_{true} log(y_{pred}) + (1-y_{true}) log(1-y_{pred})) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1: Run feed-forward and make sure it works"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2: Write a Loss Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2a: Log-loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ loss = -(y_{true} log(y_{pred}) + (1-y_{true}) log(1-y_{pred})) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_loss(ytrue, ypred):\n",
    "    loss = -(ytrue*np.log(ypred)+(1-ytrue)*np.log(1-ypred))\n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "ytrue = np.array([0.0, 0.0, 1.0, 1.0])\n",
    "ypred = np.array([0.01, 0.99, 0.01, 0.99])\n",
    "expected = np.array([0.01, 4.61, 4.61, 0.01])\n",
    "assert np.all(log_loss(ytrue, ypred).round(2) == expected)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2b: Log-loss derivative"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Formula_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_loss_deriv(ytrue, ypred):\n",
    "    loss_deriv = -(ytrue/ypred - (1-ytrue)/(1-ypred))  \n",
    "    return loss_deriv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([0.5, 0.3, 0.99, 0.2])\n",
    "b = np.array([0.4, 0.2, 0.10, 0.3])\n",
    "expected = np.array([-0.42, -0.62, -9.89, 0.48])\n",
    "assert np.all(log_loss_deriv(a, b).round(2) == expected)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Extra — 2c: Sigmoid derivative"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Formula_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid_deriv(X):\n",
    "    return sigmoid(X)*(1-sigmoid(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3: Calculate initial loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.2125982 ],\n",
       "       [1.33750334],\n",
       "       [1.49677602],\n",
       "       [1.28505593],\n",
       "       [0.19119659],\n",
       "       [1.29729941],\n",
       "       [1.54535218],\n",
       "       [1.65072577],\n",
       "       [1.46198668],\n",
       "       [0.20554232],\n",
       "       [0.22406988],\n",
       "       [0.27356366],\n",
       "       [1.30790481],\n",
       "       [0.24456463],\n",
       "       [0.27115066],\n",
       "       [0.24563753],\n",
       "       [1.27914154],\n",
       "       [1.27170628],\n",
       "       [1.27222215],\n",
       "       [0.19825694],\n",
       "       [0.257596  ],\n",
       "       [0.20280305],\n",
       "       [0.2047806 ],\n",
       "       [1.40759294],\n",
       "       [1.47997706],\n",
       "       [0.28345819],\n",
       "       [1.2737189 ],\n",
       "       [1.5562985 ],\n",
       "       [1.35088418],\n",
       "       [0.25569414],\n",
       "       [1.53008938],\n",
       "       [0.23728528],\n",
       "       [1.37840953],\n",
       "       [0.28013859],\n",
       "       [0.18456272],\n",
       "       [0.2917241 ],\n",
       "       [1.29819727],\n",
       "       [1.37320633],\n",
       "       [0.20478021],\n",
       "       [1.32927196],\n",
       "       [0.20930164],\n",
       "       [0.18428997],\n",
       "       [0.19292351],\n",
       "       [1.26105002],\n",
       "       [0.18960013],\n",
       "       [0.24705598],\n",
       "       [1.27480323],\n",
       "       [0.20557438],\n",
       "       [1.48328178],\n",
       "       [1.35178366]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out1, out2 = feed_forward(X, w)\n",
    "ytrue = y.reshape(-1, 1)\n",
    "log_loss(ytrue, out2) #which arrays do we need to compare?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = log_loss(ytrue, out2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] [0.19151908] [0.2125982]\n",
      "[1] [0.26250022] [1.33750334]\n",
      "[1] [0.22385069] [1.49677602]\n",
      "[1] [0.27663511] [1.28505593]\n",
      "[0] [0.1740298] [0.19119659]\n",
      "[1] [0.27326879] [1.29729941]\n",
      "[1] [0.21323676] [1.54535218]\n",
      "[1] [0.19191058] [1.65072577]\n",
      "[1] [0.23177535] [1.46198668]\n",
      "[0] [0.18579436] [0.20554232]\n",
      "[0] [0.20074072] [0.22406988]\n",
      "[0] [0.23933609] [0.27356366]\n",
      "[1] [0.27038597] [1.30790481]\n",
      "[0] [0.21695462] [0.24456463]\n",
      "[0] [0.23749839] [0.27115066]\n",
      "[0] [0.2177943] [0.24563753]\n",
      "[1] [0.27827609] [1.27914154]\n",
      "[1] [0.28035285] [1.27170628]\n",
      "[1] [0.28020827] [1.27222215]\n",
      "[0] [0.17984091] [0.19825694]\n",
      "[0] [0.22709258] [0.257596]\n",
      "[0] [0.18356097] [0.20280305]\n",
      "[0] [0.18517393] [0.2047806]\n",
      "[1] [0.24473166] [1.40759294]\n",
      "[1] [0.22764291] [1.47997706]\n",
      "[0] [0.24682539] [0.28345819]\n",
      "[1] [0.27978918] [1.2737189]\n",
      "[1] [0.21091533] [1.5562985]\n",
      "[1] [0.25901115] [1.35088418]\n",
      "[0] [0.22562122] [0.25569414]\n",
      "[1] [0.21651631] [1.53008938]\n",
      "[0] [0.21123376] [0.23728528]\n",
      "[1] [0.251979] [1.37840953]\n",
      "[0] [0.244321] [0.28013859]\n",
      "[0] [0.16853221] [0.18456272]\n",
      "[0] [0.2530254] [0.2917241]\n",
      "[1] [0.27302354] [1.29819727]\n",
      "[1] [0.25329351] [1.37320633]\n",
      "[0] [0.18517361] [0.20478021]\n",
      "[1] [0.26466988] [1.32927196]\n",
      "[0] [0.18884948] [0.20930164]\n",
      "[0] [0.1683054] [0.18428997]\n",
      "[0] [0.17545496] [0.19292351]\n",
      "[1] [0.28335634] [1.26105002]\n",
      "[0] [0.17271012] [0.18960013]\n",
      "[0] [0.21890303] [0.24705598]\n",
      "[1] [0.27948596] [1.27480323]\n",
      "[0] [0.18582047] [0.20557438]\n",
      "[1] [0.22689186] [1.48328178]\n",
      "[1] [0.25877828] [1.35178366]\n"
     ]
    }
   ],
   "source": [
    "[print(a, b, c) for (a,b,c) in zip(ytrue, out2, loss)];\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 4: Write a backpropagation function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fill in the blanks of the following function, which transcribes the equations from earlier (equations A - E) to run one iteration of the backpropagation algorithm. It takes in a handful of arguments:\n",
    "* the initial weights,\n",
    "* the outputs from the feed-forward process (i.e. both the hidden output and the final output),\n",
    "* the true labels,\n",
    "* the input data,\n",
    "* and the learning rates (we’ll have a separate learning rate for each layer of the network).\n",
    "\n",
    "The function (representing a single iteration of the backpropagation algorithm), should return the modified hidden weights and the modified outer weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backprop(weights,\n",
    "             output1,\n",
    "             output2,\n",
    "             ytrue,\n",
    "             X_input,\n",
    "             LR):\n",
    "\n",
    "    wH = weights[0]\n",
    "    wO = weights[1]\n",
    "\n",
    "    '''EQUATION A:'''\n",
    "    error = log_loss_deriv(ytrue , output2)\n",
    "\n",
    "    '''EQUATION B:'''\n",
    "    # don't forget the bias!\n",
    "    hidden_out_with_bias = add_bias(output1)\n",
    "    # derivative of the sigmoid function with respect to the\n",
    "    # hidden output * weights\n",
    "    sig_deriv_1 = sigmoid_deriv(output2)\n",
    "\n",
    "    y_grad = sig_deriv_1 * error\n",
    "\n",
    "    '''EQUATION C:'''\n",
    "    delta_wo = -np.dot(y_grad.T, hidden_out_with_bias ) * LR\n",
    "\n",
    "    #and finally, old weights + delta weights -> new weights!\n",
    "    wO_new = wO + delta_wo.T\n",
    "\n",
    "    '''EQUATION D:'''\n",
    "    sig_deriv_2 = sigmoid_deriv(output1)\n",
    "    #exclude the bias (last column) of the outer weights,\n",
    "    #since it is not backpropagated!\n",
    "    H_grad = sig_deriv_2 * np.dot(y_grad , ___[:-1].T)\n",
    "\n",
    "    '''EQUATION E:'''\n",
    "    delta_wH = -np.dot(H_grad.T, ___ ) * LR\n",
    "    #old weights + delta weights -> new weights!\n",
    "    wH_new = wH + delta_wH.T\n",
    "\n",
    "    # new hidden weights, new output weights\n",
    "    return ___, ___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 5: Run the Backpropagation Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run your backpropagation algorithm in a loop! Inside the loop:\n",
    "* Run your feed-forward function with the X data and the starting weights (which are initially random!).\n",
    "* Collect the total sum of the log-loss values into a list, so we can track them over time.\n",
    "* Run your backprop function to get the modified weights.\n",
    "* At the end of the loop, make your modified weights the new weights for the next cycle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup\n",
    "X, y = make_moons(n_samples=200, noise=0.1, random_state=42)\n",
    "X = add_bias(X)\n",
    "y = y.reshape(-1, 1)\n",
    "weights = [\n",
    "   np.random.normal(size=(3, 2)),\n",
    "   np.random.normal(size=(3, 1))\n",
    "]\n",
    "\n",
    "# train\n",
    "LOSS_VEC = []\n",
    "\n",
    "for i in range(1000):\n",
    "    out1, out2 = feed_forward(X, weights)\n",
    "    LOSS_VEC.append(___.sum())\n",
    "    new_weights = backprop(___, ___, ___, ___, ___, ___)\n",
    "    weights = ___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 6: Plot results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 6a: Plot loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(LOSS_VEC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 6b: Plot decision boundary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a grid of values\n",
    "x = np.linspace(-3, 3, 200)\n",
    "X_vis = np.array([(x1, x2) for x1 in x for x2 in x])\n",
    "# add the bias column\n",
    "X_vis = add_bias(X_vis)\n",
    "\n",
    "# calculate the (random) predictions\n",
    "_, y_pred = feed_forward(X_vis, weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape the predictions for visualization\n",
    "Z = y_pred.reshape((len(x), len(x)), order='F')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw a contour plot\n",
    "fig,ax=plt.subplots(1,1)\n",
    "cp = ax.contourf(x, x, Z, alpha=0.8, cmap='coolwarm')\n",
    "ax.contour(x, x, Z, levels=[0.5])\n",
    "fig.colorbar(cp) # Add a colorbar to a plot\n",
    "\n",
    "# draw the original data\n",
    "X, y = make_moons(n_samples=200, noise=0.1, random_state=42)\n",
    "ax.scatter(X[:,0], X[:,1], c=y, cmap='coolwarm')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
